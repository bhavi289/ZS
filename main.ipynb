{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, average_precision_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/bhavi/Documents/Projects/CristianoRonaldo/Cristano_Ronaldo_Final_v1/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'lat/lng':'lat_lng',\\\n",
    "                        'distance_of_shot.1': 'distance_of_shot_1', \\\n",
    "                        'remaining_min.1':'remaining_min_1', \\\n",
    "                        'power_of_shot.1':'power_of_shot_1', \\\n",
    "                        'knockout_match.1' : 'knockout_match_1', \\\n",
    "                        'remaining_sec.1' : 'remaining_sec_1'})\n",
    "\n",
    "\n",
    "print (df[df.match_id.isnull()].shape) # match_id is never null\n",
    "\n",
    "\n",
    "for col in df.columns:\n",
    "    print (f\"'{col}'\", end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.scatter_matrix(df[['match_event_id','remaining_min','remaining_sec', 'remaining_min_1', 'remaining_sec_1', 'distance_of_shot_1']], alpha=0.6, figsize=(10, 10), diagonal='kde')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Filling Missing Values of game_season by padding on previous values\n",
    "'''\n",
    "\n",
    "print(df[df.game_season.isnull()].shape)\n",
    "df['game_season'] = df['game_season'].fillna(method='pad')\n",
    "\n",
    "df['game_season'] = df['game_season'].apply(\n",
    "    lambda x: x.split('-')[0]\n",
    ")\n",
    "\n",
    "print(df[df.game_season.isnull()].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Filling Missing Values of date_of_game by padding on previous values\n",
    "'''\n",
    "\n",
    "print(df[df.date_of_game.isnull()].shape)\n",
    "df['date_of_game'] = df['date_of_game'].fillna(method='pad')\n",
    "\n",
    "print(df[df.date_of_game.isnull()].shape)\n",
    "\n",
    "'''\n",
    "    Generating new features for day month and year\n",
    "'''\n",
    "\n",
    "df['day'] = df['date_of_game'].apply(\n",
    "    lambda x: x.split('-')[0]\n",
    ")\n",
    "\n",
    "df['month'] = df['date_of_game'].apply(\n",
    "    lambda x: x.split('-')[1]\n",
    ")\n",
    "\n",
    "df['year'] = df['date_of_game'].apply(\n",
    "    lambda x: x.split('-')[2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Filling Missing Values of lat_lng by padding on previous values\n",
    "'''\n",
    "\n",
    "print(df[df.lat_lng.isnull()].shape)\n",
    "df['lat_lng'] = df['lat_lng'].fillna(method='pad')\n",
    "\n",
    "print(df[df.lat_lng.isnull()].shape)\n",
    "\n",
    "'''\n",
    "    lat_lng is categorical based on arena of match - we can label encode it\n",
    "'''\n",
    "print(df.lat_lng.unique().shape)\n",
    "df['lat_lng'] = df['lat_lng'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match Event Id\n",
    "\n",
    "# for i in range(2, len(df[df.match_event_id.isnull()])):\n",
    "#     df.loc[i, 'match_event_id'] = df.loc[i-1, 'match_event_id']\n",
    "\n",
    "'''\n",
    "    Fill Missing Match Event Id By Looking at Row Above And Below with same Game Id,\n",
    "    pass in case of any error.\n",
    "'''\n",
    "for index, row in df[df.match_event_id.isnull()].iterrows():\n",
    "    try:\n",
    "        if df.loc[index - 1, 'match_id'] == row['match_id']:\n",
    "            df.loc[index, 'match_event_id'] = int(df.loc[index-1, 'match_event_id']) + 1\n",
    "        elif df.loc[index + 1, 'match_id'] == row['match_id']:\n",
    "            df.loc[index, 'match_event_id'] = int(df.loc[index+1, 'match_event_id']) + 1\n",
    "        else:\n",
    "            df.loc[index, 'match_event_id'] = int(df.loc[index-1, 'match_event_id']) + 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "'''\n",
    "    Fill Remaining Rows(only 10) with mode value\n",
    "'''\n",
    "df['match_event_id'] = df['match_event_id'].fillna(method='pad')\n",
    "# df['match_event_id'].fillna(df['match_event_id'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Filling Missing Valued For Knockout Matches\n",
    "'''\n",
    "def fillKnockoutMatches(row):\n",
    "    if row.name >= 26198:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['knockout_match'] = df['knockout_match'].fillna(method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Filling some Distance Of Shot Feature values based on another feature by the same name.\n",
    "    Second feature has noise in form of decimal numbers, so making sure that is not used\n",
    "'''\n",
    "\n",
    "df['distance_of_shot'] = df.apply(\n",
    "    lambda row: row['distance_of_shot_1'] if np.isnan(row['distance_of_shot']) and (row['distance_of_shot_1']).is_integer() else row['distance_of_shot'],\n",
    "    axis=1\n",
    ")\n",
    "# Filling remaing missing distance values with mean\n",
    "df['distance_of_shot'].fillna(df['distance_of_shot'].mean(), inplace=True)\n",
    "\n",
    "\n",
    "df['remaining_min'] = df.apply(\n",
    "    lambda row: row['remaining_min_1'] if np.isnan(row['remaining_min']) and (row['remaining_min_1']).is_integer() else row['remaining_min'],\n",
    "    axis=1\n",
    ")\n",
    "'''\n",
    "    Time Remaining has no significant correlation with any of the features. Replacing missing \n",
    "    values of it by mean value of feature\n",
    "'''\n",
    "df['remaining_min'].fillna(df['remaining_min'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Preprocessing area field to contain only area abbreviation\n",
    "'''\n",
    "def findArea(x):\n",
    "    if type(x) == float and np.isnan(x):\n",
    "        return x\n",
    "    else:\n",
    "        return x.split('(')[1].split(')')[0]\n",
    "\n",
    "df[\"area_of_shot\"] = df[\"area_of_shot\"].apply(findArea)\n",
    "\n",
    "'''\n",
    "    Label encoding area of shot. It encodes NaN value as -1. This will be handled as a different category when we One Hot Encode this while training.\n",
    "'''\n",
    "\n",
    "# print(df['area_of_shot'])\n",
    "df['area_of_shot'].fillna(\"Unique\", inplace=True) #Replacing NaN values with a unique value(quite literally)\n",
    "df['area_of_shot'] = df['area_of_shot'].astype('category').cat.codes\n",
    "# print(df['area_of_shot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Preprocessing Range of Shot to give lower and upper range\n",
    "'''\n",
    "def processRangeOfShot(row):\n",
    "    range_of_shot = str(row['range_of_shot'])\n",
    "    try:\n",
    "        if \"Less Than\" in range_of_shot:\n",
    "            return 0, 8\n",
    "        elif \"+\" in range_of_shot:\n",
    "            return 24, 32\n",
    "        else:\n",
    "            low = range_of_shot.split('-')[0]\n",
    "            high = range_of_shot.split('-')[1][0:2]\n",
    "            return low, high\n",
    "    except Exception as e:\n",
    "        return float('NaN'), float('NaN')\n",
    "    \n",
    "df['lower_range'], df['upper_range'] = zip(*df.apply(processRangeOfShot, axis=1))\n",
    "\n",
    "'''\n",
    "    Filling Remaining values with mode of feature\n",
    "'''\n",
    "\n",
    "df['lower_range'].fillna(df['lower_range'].mode()[0], inplace=True)\n",
    "df['upper_range'].fillna(df['upper_range'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Processing Home/away\n",
    "'''\n",
    "def processHome(row):\n",
    "    val = row['home/away']\n",
    "    try:\n",
    "        if '@' in val:\n",
    "            return 0\n",
    "        elif 'vs' in val:\n",
    "            return 1\n",
    "    except:\n",
    "        return val\n",
    "    \n",
    "df['home'] = df.apply(processHome, axis=1)\n",
    "\n",
    "'''\n",
    "    Filling Missing Values\n",
    "'''\n",
    "df['home'] = df['home'].fillna(method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    One of 'type_of_shot' and 'type_of_combined_shot' is always present in data\n",
    "'''\n",
    "\n",
    "print(df[df.type_of_shot.isnull() & df.type_of_combined_shot.isnull()].shape)\n",
    "\n",
    "'''\n",
    "    Label encoding type_of_shot and type_of_combined_shot. It encodes NaN value as -1. This will be handled when we One Hot Encode this while training.\n",
    "'''\n",
    "df['type_of_shot'].fillna(\"Unique\", inplace=True) #Replacing NaN values with a unique value(quite literally)\n",
    "df['type_of_shot'] = df['type_of_shot'].astype('category').cat.codes\n",
    "\n",
    "df['type_of_combined_shot'].fillna(\"Unique\", inplace=True) #Replacing NaN values with a unique value(quite literally)\n",
    "df['type_of_combined_shot'] = df['type_of_combined_shot'].astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Filling Missing data with mode and then label encoding\n",
    "'''\n",
    "\n",
    "df['shot_basics'].fillna(df['shot_basics'].mode()[0], inplace=True)\n",
    "df['shot_basics'] = df['shot_basics'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print (f\"'{col}'\", end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Finding Missing Values Of power_of_shot which has high correlation with match_event_id by a logistic regression model\n",
    "'''\n",
    "def logisticRegressionForPowerOfShot(data):    \n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    linreg = LogisticRegression()\n",
    "\n",
    "    sub = data[data.power_of_shot.notnull()]\n",
    "    sub = sub[sub.match_event_id.notnull()]\n",
    "    X_train = sub[['match_event_id']]\n",
    "    y_train = sub[['power_of_shot']]\n",
    "\n",
    "    sub = data[data.power_of_shot.isnull()]\n",
    "    sub = sub[sub.match_event_id.notnull()]\n",
    "    X_test = sub[['match_event_id']]\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "\n",
    "    linreg.fit(X_train, y_train)\n",
    "\n",
    "    predicted = linreg.predict(X_test)\n",
    "\n",
    "    print (data[data.power_of_shot.isnull()].shape, predicted.shape)\n",
    "\n",
    "    print (predicted.mean(), data[data.power_of_shot.notnull()]['power_of_shot'].mean())\n",
    "\n",
    "    data.loc[data.power_of_shot.isnull() & data.match_event_id.notnull() , 'power_of_shot'] = predicted \n",
    "    \n",
    "    return data\n",
    "\n",
    "df = logisticRegressionForPowerOfShot(df.copy())\n",
    "\n",
    "# df = df.drop(df[df.location_x.isnull()].index)\n",
    "\n",
    "df['power_of_shot'].fillna(df['power_of_shot'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['location_x', 'location_y', 'distance_of_shot']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Finding Missing Values Of Location_x by a linear regression model\n",
    "'''\n",
    "def linearRegressionForLocation_X(data):    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    linreg = LinearRegression()\n",
    "\n",
    "    sub = data[data.location_x.notnull()]\n",
    "    sub = sub[sub.location_y.notnull()][sub.distance_of_shot.notnull()][sub.lower_range.notnull()][sub.upper_range.notnull()]\n",
    "    X_train = sub[['location_y', 'distance_of_shot', 'lower_range', 'upper_range']]\n",
    "    y_train = sub[['location_x']]\n",
    "\n",
    "    sub = data[data.location_x.isnull()]\n",
    "    sub = sub[sub.location_y.notnull()][sub.distance_of_shot.notnull()][sub.lower_range.notnull()][sub.upper_range.notnull()]\n",
    "    X_test = sub[['location_y', 'distance_of_shot', 'lower_range', 'upper_range']]\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "\n",
    "    linreg.fit(X_train, y_train)\n",
    "\n",
    "    predicted = linreg.predict(X_test)\n",
    "\n",
    "    print (data[data.location_x.isnull()].shape, predicted.shape)\n",
    "\n",
    "    print (predicted.mean(), data[data.location_x.notnull()]['location_x'].mean())\n",
    "\n",
    "    data.loc[data.location_x.isnull() & \\\n",
    "             data.location_y.notnull() & \\\n",
    "            data.distance_of_shot.notnull() & \\\n",
    "            data.lower_range.notnull() & \\\n",
    "            data.upper_range.notnull(), 'location_x'] = predicted \n",
    "    \n",
    "    return data\n",
    "\n",
    "df = linearRegressionForLocation_X(df.copy())\n",
    "\n",
    "# df = df.drop(df[df.location_x.isnull()].index)\n",
    "\n",
    "df['location_x'].fillna(df['location_x'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Finding Missing Values Of Location_y by a linear regression model\n",
    "'''\n",
    "def linearRegressionForLocation_Y(data):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    linreg = LinearRegression()\n",
    "\n",
    "    sub = data[data.location_y.notnull()]\n",
    "    sub = sub[sub.location_x.notnull()][sub.distance_of_shot.notnull()][sub.lower_range.notnull()][sub.upper_range.notnull()]\n",
    "    X_train = sub[['location_x', 'distance_of_shot', 'lower_range', 'upper_range']]\n",
    "    y_train = sub[['location_y']]\n",
    "\n",
    "    print (X_train.shape, y_train.shape)\n",
    "\n",
    "    sub = data[data.location_y.isnull()]\n",
    "    sub = sub[sub.location_x.notnull()][sub.distance_of_shot.notnull()][sub.lower_range.notnull()][sub.upper_range.notnull()]\n",
    "    X_test = sub[['location_x', 'distance_of_shot', 'lower_range', 'upper_range']]\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "\n",
    "    linreg.fit(X_train, y_train)\n",
    "\n",
    "    predicted = linreg.predict(X_test)\n",
    "\n",
    "    print (data[data.location_y.isnull()].shape, predicted.shape)\n",
    "\n",
    "    print (predicted.mean(), data[data.location_y.notnull()]['location_y'].mean())\n",
    "\n",
    "    data.loc[data.location_y.isnull() & \\\n",
    "             data.location_x.notnull() & \\\n",
    "            data.distance_of_shot.notnull() & \\\n",
    "            data.lower_range.notnull() & \\\n",
    "            data.upper_range.notnull(), 'location_y'] = predicted \n",
    "    return data\n",
    "\n",
    "df = linearRegressionForLocation_Y(df.copy())\n",
    "\n",
    "# df = df.drop(df[df.location_y.isnull()].index)\n",
    "\n",
    "df['location_y'].fillna(df['location_y'].mean(), inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df[df.match_event_id.isnull()].shape,\\\n",
    "       df[df.location_x.isnull()].shape,\\\n",
    "       df[df.location_y.isnull()].shape,\\\n",
    "       df[df.remaining_min.isnull()].shape,\\\n",
    "       df[df.power_of_shot.isnull()].shape,\\\n",
    "       df[df.knockout_match.isnull()].shape,\\\n",
    "       df[df.distance_of_shot.isnull()].shape,\\\n",
    "       df[df.area_of_shot.isnull()].shape,\\\n",
    "       df[df.shot_basics.isnull()].shape,\\\n",
    "       df[df.lower_range.isnull()].shape,\\\n",
    "       df[df.upper_range.isnull()].shape,\\\n",
    "       df[df.type_of_shot.isnull()].shape,\\\n",
    "       df[df.type_of_combined_shot.isnull()].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = old_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print (f\"'{col}'\", end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Univariate Selection\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "considering_features = ['match_event_id','location_x','location_y'\\\n",
    "                        ,'remaining_min','power_of_shot','knockout_match'\\\n",
    "                        ,'game_season', 'distance_of_shot','area_of_shot'\\\n",
    "                        ,'shot_basics','lat_lng','type_of_shot'\\\n",
    "                        ,'type_of_combined_shot', 'month','year','lower_range'\\\n",
    "                        ,'upper_range','home',\\\n",
    "                        'is_goal', 'shot_id_number'] # These 2 are not considered as training features\n",
    "\n",
    "\n",
    "\n",
    "dt = df[df.is_goal.notnull()]\n",
    "\n",
    "dt = dt[considering_features]\n",
    "\n",
    "X = dt.loc[:, (dt.columns != 'is_goal') & (dt.columns != 'shot_id_number') ]\n",
    "cols = X.columns\n",
    "\n",
    "y = dt[['is_goal']]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X = min_max_scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "X.columns = cols\n",
    "\n",
    "\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns, dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(19,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Correlation Matrix with Heatmap\n",
    "'''\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "considering_features = ['match_event_id','location_x','location_y'\\\n",
    "                        ,'remaining_min','power_of_shot','knockout_match'\\\n",
    "                        ,'game_season', 'distance_of_shot','area_of_shot'\\\n",
    "                        ,'shot_basics','lat_lng','type_of_shot'\\\n",
    "                        ,'type_of_combined_shot', 'month','year','lower_range'\\\n",
    "                        ,'upper_range','home',\\\n",
    "                        'is_goal', 'shot_id_number'] # These 2 are not considered as training features\n",
    "\n",
    "\n",
    "dt = df.copy()\n",
    "\n",
    "dt = dt[considering_features]\n",
    "\n",
    "#get correlations of each features in dataset\n",
    "corrmat = dt.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g = sns.heatmap(dt[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# considering_features = ['match_event_id','location_x','location_y'\\\n",
    "#                         ,'remaining_min','power_of_shot','knockout_match'\\\n",
    "#                         ,'game_season', 'distance_of_shot','area_of_shot'\\\n",
    "#                         ,'shot_basics','lat_lng','type_of_shot'\\\n",
    "#                         ,'type_of_combined_shot', 'month','year','lower_range'\\\n",
    "#                         ,'upper_range','home',\\\n",
    "#                         'is_goal', 'shot_id_number'] # These 2 are not considered as training features\n",
    "\n",
    "# categorical_features = ['power_of_shot', 'knockout_match', 'game_season', 'area_of_shot' ,'shot_basics'\\\n",
    "#                        ,'lat_lng', 'type_of_shot', 'type_of_combined_shot', 'month','year','lower_range'\\\n",
    "#                         ,'upper_range','home']\n",
    "\n",
    "\n",
    "considering_features = ['match_event_id','location_x','location_y'\\\n",
    "                        ,'remaining_min','power_of_shot','knockout_match'\\\n",
    "                        , 'distance_of_shot','area_of_shot'\\\n",
    "                        ,'shot_basics','type_of_shot'\\\n",
    "                        ,'type_of_combined_shot','lower_range'\\\n",
    "                        ,'upper_range','home','month',\\\n",
    "                        'is_goal', 'shot_id_number'] # These 2 are not considered as training features\n",
    "\n",
    "categorical_features = ['power_of_shot', 'area_of_shot'\\\n",
    "                       , 'type_of_shot', 'type_of_combined_shot','lower_range'\\\n",
    "                        ,'upper_range','home','month','knockout_match']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    One Hot Encoding\n",
    "'''\n",
    "df = df[considering_features]\n",
    "\n",
    "encoded = pd.get_dummies(data=df, columns = categorical_features)\n",
    "encoded.columns = encoded.columns.str.replace(\".\", \"_\")\n",
    "encoded.columns = encoded.columns.str.replace(\"-\", \"_\")\n",
    "\n",
    "for col in encoded.columns:\n",
    "    print (f\"'{col}'\", end=',')\n",
    "df = encoded\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df[df.is_goal.isnull()]\n",
    "submission = submission.copy()\n",
    "submission.loc[:, 'shot_id_number'] = submission.index + 1\n",
    "\n",
    "submission.to_csv(\"TestData.csv\", index=False)\n",
    "data = df[df.is_goal.notnull()]\n",
    "df.shape, data.shape, submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, (data.columns != 'is_goal') & (data.columns != 'shot_id_number') ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPrecisionRecallCurve(y_test, y_pred, average_precision):\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    import matplotlib.pyplot as plt\n",
    "    from inspect import signature\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "                   if 'step' in signature(plt.fill_between).parameters\n",
    "                   else {})\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "              average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotROCCurve(y_test, y_pred, model):\n",
    "    import sklearn.metrics as metrics\n",
    "    # calculate the fpr and tpr for all thresholds of the classification\n",
    "    probs = model.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    # method I: plt\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatePredictions(y_test, y_pred, y_train, y_pred_train, classifier):\n",
    "    # Making the Confusion Matrix\n",
    "    cm_test = confusion_matrix(y_test, y_pred)\n",
    "    cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    \n",
    "    average_precision = average_precision_score(y_test, y_pred)\n",
    "    print (f\"{cm_test} \\n {accuracy_test} \\n\\n {cm_train} \\n {accuracy_train} \\n\\nPrecision Recall Score = {average_precision} \")\n",
    "    print (f\"\\n\\nClassification Report\\n {classification_report(y_test, y_pred)}\\n\")\n",
    "    plotROCCurve(y_test, y_pred, classifier)\n",
    "#     plotPrecisionRecallCurve(y_test, y_pred, average_precision)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = data.loc[:, (data.columns != 'is_goal') & (data.columns != 'shot_id_number') ].columns\n",
    "# X = data.loc[:, (data.columns != 'is_goal') & (data.columns != 'shot_id_number') ].values\n",
    "# y = data[['is_goal']].values\n",
    "\n",
    "# ratio = (len(y) - y.sum()) / (y.sum())\n",
    "# print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = data.loc[:, (data.columns != 'is_goal') & (data.columns != 'shot_id_number') ].columns\n",
    "X = data.loc[:, (data.columns != 'is_goal') & (data.columns != 'shot_id_number') ].values\n",
    "y = data[['is_goal']].values\n",
    "\n",
    "ratio = (len(y) - y.sum()) / (y.sum())\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# ct = ColumnTransformer(\n",
    "#     [('one_hot_encoder', OneHotEncoder(), [5, 6, 7, 8, 10, 11])],    # The column numbers to be transformed (here is [0] but can be [0, 1, 3])\n",
    "#     remainder='passthrough'                         # Leave the rest of the columns untouched\n",
    "# )\n",
    "\n",
    "# X = np.array(ct.fit_transform(X), dtype=np.float)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0) # from 10 observations- 2 in test set and 8 in training set, random state is not necessary\n",
    "\n",
    "''' Feature Scaling '''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train =sc_X.fit_transform(X_train)\n",
    "X_test =sc_X.transform(X_test)\n",
    "# debate on scaling dummy variablesm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression(random_state = 0)\n",
    "logistic.fit(X_train, y_train)\n",
    "y_pred_train = logistic.predict(X_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = logistic.predict(X_test)\n",
    "\n",
    "evaluatePredictions(y_test, y_pred, y_train, y_pred_train, logistic)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "xboost_classifier = XGBClassifier(random_state = 0, scale_pos_weight=ratio)\n",
    "xboost_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = xboost_classifier.predict(X_train)\n",
    "y_pred = xboost_classifier.predict(X_test)\n",
    "\n",
    "evaluatePredictions(y_test, y_pred, y_train, y_pred_train, xboost_classifier)\n",
    "probs = xboost_classifier.predict_proba(X_test)\n",
    "\n",
    "# print(xboost_classifier.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "plt.figure(figsize=(20,15))\n",
    "feat_importances = pd.Series(xboost_classifier.feature_importances_, index=cols)\n",
    "feat_importances.nlargest(30).plot(kind='barh')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_train = classifier.predict(X_train)\n",
    "# y_pred = classifier.predict(X_test)\n",
    "\n",
    "# evaluatePredictions(y_test, y_pred, y_train, y_pred_train, classifier)\n",
    "\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# classifier = KNeighborsClassifier(n_neighbors = 20, metric = 'minkowski', p = 2)\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_train = classifier.predict(X_train)\n",
    "# y_pred = classifier.predict(X_test)\n",
    "\n",
    "# evaluatePredictions(y_test, y_pred, y_train, y_pred_train, classifier)\n",
    "\n",
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_train = classifier.predict(X_train)\n",
    "# y_pred = classifier.predict(X_test)\n",
    "\n",
    "# evaluatePredictions(y_test, y_pred, y_train, y_pred_train, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Parameter Tuning XGBoost\n",
    "'''\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV  #Perforing grid search\n",
    "# from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "# from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "cols = data.loc[:, (data.columns != 'is_goal') & (data.columns != 'shot_id_number') ].columns\n",
    "train = data.loc[:, (data.columns != 'shot_id_number') ]\n",
    "y = data[['is_goal']].values\n",
    "\n",
    "target = 'is_goal'\n",
    "IDcol = 'ID'\n",
    "\n",
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'],\\\n",
    "                          nfold=cv_folds,metrics='auc', early_stopping_rounds=early_stopping_rounds,\\\n",
    "                          )\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['is_goal'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['is_goal'].values, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['is_goal'], dtrain_predprob))\n",
    "                    \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    \n",
    "#Choose all predictors except target & IDcols\n",
    "predictors = train.columns\n",
    "\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, train, predictors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = submission.loc[:, (data.columns != 'is_goal') & (data.columns != 'shot_id_number') ].values\n",
    "y = submission[['is_goal']].values\n",
    "\n",
    "# ''' Feature Scaling '''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X =sc_X.fit_transform(X)\n",
    "\n",
    "probs = xboost_classifier.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = pd.DataFrame(columns=['shot_id_number', 'is_goal'])\n",
    "\n",
    "solution['shot_id_number'] = submission['shot_id_number']\n",
    "solution['is_goal'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.to_csv(\"bhavi_chawla_280998_code_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script main.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
